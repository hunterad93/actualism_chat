{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook can be used to clean your openai file database, it finds files with duplicate names, and then it can optionally (final cell) delete all duplicates except for the newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "# Initialize the OpenAI client\n",
    "import os\n",
    "import pandas as pd\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all duplicate filenames, count how many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files\n",
    "response = client.files.list()\n",
    "\n",
    "# Dictionary to track all versions of each file\n",
    "all_files_dict = {}\n",
    "\n",
    "# Populate the dictionary with all versions of each file\n",
    "for file in response.data:\n",
    "    if file.filename in all_files_dict:\n",
    "        all_files_dict[file.filename].append(file)\n",
    "    else:\n",
    "        all_files_dict[file.filename] = [file]\n",
    "\n",
    "# Filter out non-duplicates and prepare data for DataFrame\n",
    "duplicates = {filename: files for filename, files in all_files_dict.items() if len(files) > 1}\n",
    "\n",
    "# Displaying the count of duplicated filenames\n",
    "print(f\"Count of duplicated filenames: {len(duplicates)}\")\n",
    "\n",
    "# Displaying the total count of files\n",
    "print(f\"Total count of files: {len(response.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display a df of duplicated files with number of times duped, first and last version timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for DataFrame\n",
    "data_for_df = []\n",
    "for filename, files in duplicates.items():\n",
    "    oldest = min(files, key=lambda x: x.created_at)\n",
    "    newest = max(files, key=lambda x: x.created_at)\n",
    "    data_for_df.append({\n",
    "        'Filename': filename,\n",
    "        'Count': len(files),\n",
    "        'Oldest Created At': oldest.created_at,\n",
    "        'Newest Created At': newest.created_at\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_for_df)\n",
    "df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If everything is fine, next cell keeps only newest of each name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Proceed with deletion\n",
    "for filename, files in duplicates.items():\n",
    "    files.sort(key=lambda x: x.created_at)\n",
    "    # Skip the newest file, delete all others\n",
    "    for file in files[:-1]:\n",
    "        client.files.delete(file.id)\n",
    "        print(f\"Deleted older file {file.filename} with ID {file.id}\")\n",
    "\n",
    "print(\"Duplicate file analysis completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
